-----------
# DISTRIBUTED COMPUTING WITH SPARK SQL
-----------
## Module 1 - Introduction to Spark
> Learning Objectives
> * Why Spark and Distributed Computing?
> * Spark Dataframes
> * Databricks collaborative workspace with SQL

__The 5 V's:__
* Volume
* Velocity
* Variety
* Veracity
* Value

Apache Spark: The Unified Analytics Engine

Spark is the open-source industry standard tool for manipulating big data 
* It connects to a large number of data sources
* It works with SQL, Python, R, and Scala/ Java
* It distributes computation across a cluster of networked computers

RDD
* Resilient - Fault-tolerant, DAG (directed acyclic graph)
* Distributed - Computed across multiple nodes

-----------
## Module 2 - Spark Core Concepts
> Learning Objectives
> * Storage and Compute
> * Caching
> * Partitions
> * Spark UI

 
-----------
## Module 3 - Engineering Data Pipeline
> Learning Objectives
> * Connecting to Databases
> * Schemas and Types
> * File Formats
> * Writing Data

-----------
## Module 4 - Data Lakes, Warehouse, and Lakehouses
> Learning Objectives
> * Data Warehouse and Data lakes
> * The data lakehouse
> * Delta lake for data management
> * Continuing on to Data Science
